{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabvald/Vision-Project-Image-Segmentation/blob/master/VGG-16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GGdDzNp-gEg"
      },
      "source": [
        "### In the lecture you have been introduced to VGG16. For this problem your task is to implement a VGG like CNN architecture for classification on the CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQs8RyYL9nUc"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1lFcXIXgbac",
        "outputId": "88f23e72-f08d-4a2a-e3f8-329ddc67147c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_workers = 2\n",
        "batch_size = 16\n",
        "%config Completer.use_jedi = False"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD3VxyUggbac"
      },
      "source": [
        "torch.cuda.init()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ1AZfUD_HZ9"
      },
      "source": [
        "### 1. Load the dataset (0.5 point)\n",
        "To load the dataset, you can use the inbuilt dataloader for CIFAR10 provided in the torchvision package. Load both test set and trainset separately. Define the transformations you might need to load the data appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOSZHQRT9nUr",
        "outputId": "b8183b4d-ba57-478e-ecc9-5c2c5db28d1c"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./CIFAR10', train = True,\n",
        "                                        download = True, transform = transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, \n",
        "                                            shuffle = True, num_workers = num_workers)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./CIFAR10', train = False,\n",
        "                                        download = True, transform = transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, \n",
        "                                            shuffle = True, num_workers = num_workers)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCudIb4xgbag",
        "outputId": "1da9c77f-d7a8-40b4-90de-00bfab3ef8b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(trainset))\n",
        "print(trainset[0][0].size())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "torch.Size([3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGpxcaoc_te7"
      },
      "source": [
        "### Create the model architecture (1.0 point)\n",
        "Implement the class below such that the final architecture follows the same pattern of layers as VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeCGIwT99nUs"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(2, stride = 2, padding = 0)\n",
        "\n",
        "        self.fc1 = nn.Linear(256*4*4, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.max_pool(self.conv1_2(x))\n",
        "        x = self.conv2_1(x) \n",
        "        x = self.max_pool(self.conv2_2(x))\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.max_pool(self.conv3_2(x))\n",
        "        x = x.view(-1, 256*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        out = self.fc3(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "net = Net().cuda()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNC9ujQAJY6"
      },
      "source": [
        "### Loss function and optimizer (0.5 point)\n",
        "Define the loss function and optimizer to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5bALqHB9nUt"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWmCHNJSAUe1"
      },
      "source": [
        "### Train the model (1.0 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF7eNJ389nUt",
        "outputId": "24118579-9c03-40a1-dc2a-2c4a8865a815"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs): \n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Reset gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Feed forward \n",
        "        outputs = net.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics \n",
        "        running_loss += loss.item()\n",
        "        if i % 500 == 499:    # print every 500 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 500))\n",
        "            running_loss = 0.0\n",
        "        \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.301\n",
            "[1,  1000] loss: 2.254\n",
            "[1,  1500] loss: 2.074\n",
            "[1,  2000] loss: 1.987\n",
            "[1,  2500] loss: 1.872\n",
            "[1,  3000] loss: 1.734\n",
            "[2,   500] loss: 1.644\n",
            "[2,  1000] loss: 1.560\n",
            "[2,  1500] loss: 1.517\n",
            "[2,  2000] loss: 1.461\n",
            "[2,  2500] loss: 1.438\n",
            "[2,  3000] loss: 1.399\n",
            "[3,   500] loss: 1.298\n",
            "[3,  1000] loss: 1.283\n",
            "[3,  1500] loss: 1.230\n",
            "[3,  2000] loss: 1.199\n",
            "[3,  2500] loss: 1.168\n",
            "[3,  3000] loss: 1.137\n",
            "[4,   500] loss: 1.036\n",
            "[4,  1000] loss: 1.042\n",
            "[4,  1500] loss: 1.039\n",
            "[4,  2000] loss: 0.995\n",
            "[4,  2500] loss: 0.974\n",
            "[4,  3000] loss: 0.959\n",
            "[5,   500] loss: 0.874\n",
            "[5,  1000] loss: 0.860\n",
            "[5,  1500] loss: 0.868\n",
            "[5,  2000] loss: 0.850\n",
            "[5,  2500] loss: 0.866\n",
            "[5,  3000] loss: 0.822\n",
            "[6,   500] loss: 0.752\n",
            "[6,  1000] loss: 0.724\n",
            "[6,  1500] loss: 0.765\n",
            "[6,  2000] loss: 0.757\n",
            "[6,  2500] loss: 0.768\n",
            "[6,  3000] loss: 0.738\n",
            "[7,   500] loss: 0.655\n",
            "[7,  1000] loss: 0.670\n",
            "[7,  1500] loss: 0.678\n",
            "[7,  2000] loss: 0.664\n",
            "[7,  2500] loss: 0.627\n",
            "[7,  3000] loss: 0.670\n",
            "[8,   500] loss: 0.557\n",
            "[8,  1000] loss: 0.566\n",
            "[8,  1500] loss: 0.580\n",
            "[8,  2000] loss: 0.589\n",
            "[8,  2500] loss: 0.600\n",
            "[8,  3000] loss: 0.597\n",
            "[9,   500] loss: 0.496\n",
            "[9,  1000] loss: 0.494\n",
            "[9,  1500] loss: 0.518\n",
            "[9,  2000] loss: 0.504\n",
            "[9,  2500] loss: 0.536\n",
            "[9,  3000] loss: 0.534\n",
            "[10,   500] loss: 0.420\n",
            "[10,  1000] loss: 0.427\n",
            "[10,  1500] loss: 0.441\n",
            "[10,  2000] loss: 0.456\n",
            "[10,  2500] loss: 0.462\n",
            "[10,  3000] loss: 0.471\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLlqZjZiA5nf"
      },
      "source": [
        "Code below generates the class wise accuracy of the model. You can use the results from the code below to decide the values of hyperparametrs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ughmKpRj9nUu",
        "outputId": "95304789-95e3-4c5e-a389-18a0658323ec"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "global_accuracy = 0.0\n",
        "\n",
        "net.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    global_accuracy +=  100 * class_correct[i] / class_total[i] * class_total[i] / len(testset)\n",
        "\n",
        "print('\\nGlobal accuracy   : %2d %%' % global_accuracy)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 83 %\n",
            "Accuracy of   car : 90 %\n",
            "Accuracy of  bird : 65 %\n",
            "Accuracy of   cat : 63 %\n",
            "Accuracy of  deer : 79 %\n",
            "Accuracy of   dog : 73 %\n",
            "Accuracy of  frog : 84 %\n",
            "Accuracy of horse : 74 %\n",
            "Accuracy of  ship : 83 %\n",
            "Accuracy of truck : 80 %\n",
            "\n",
            "Global accuracy   : 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}